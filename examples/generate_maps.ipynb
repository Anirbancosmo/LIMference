{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54712fd8-4f7c-42b3-b700-eef8457fa28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE 1: VARYING COSMOLOGY MODE\n",
      "Uses different halo catalogs for each parameter combination\n",
      "================================================================================\n",
      "Mode: varying_cosmology\n",
      "Parameters to vary: ['sigma_8', 'omega_m', 'a_off', 'b_off']\n",
      "  Cosmological: ['sigma_8', 'omega_m']\n",
      "  Astrophysical: ['a_off', 'b_off']\n",
      "Noise mode: fixed\n",
      "\n",
      "Processing 3000 halo catalogs\n",
      "Each catalog provides its own cosmology (sigma_8, omega_m)\n",
      "Astrophysical parameters (a_off, b_off) are sampled via Latin hypercube\n",
      "Store maps in memory: True\n",
      "Output directory: /Users/anirbanroy/Desktop/test_maps_all_params/\n",
      "Generated 3000 Latin hypercube samples for ['a_off', 'b_off']\n",
      "  a_off: [4.001, 9.999]\n",
      "  b_off: [0.000, 2.000]\n",
      "\n",
      "Processing 3000 halocats with varying cosmology\n",
      "Store maps: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████| 3000/3000 [05:11<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stored 3000 maps in memory\n",
      "\n",
      "Saving 3000 intensity maps to disk...\n",
      "  Intensity maps: /Users/anirbanroy/Desktop/test_maps_all_params/intensity_maps_80_256.npz\n",
      "  File size: ~1.50 GB\n",
      "\n",
      "Results saved:\n",
      "  Power spectra: /Users/anirbanroy/Desktop/test_maps_all_params/ps_80_256.npz\n",
      "  PDFs: /Users/anirbanroy/Desktop/test_maps_all_params/pdf_80_256.npz\n",
      "  Config: /Users/anirbanroy/Desktop/test_maps_all_params/parameter_config.json\n",
      "\n",
      "Mode: varying_cosmology\n",
      "Seed: 42\n",
      "Maps stored in memory: 3000\n",
      "\n",
      "Parameter summary (3000 samples):\n",
      "  sigma_8: [0.400, 1.200]\n",
      "  omega_m: [0.100, 0.600]\n",
      "  a_off: [4.001, 9.999]\n",
      "  b_off: [0.000, 2.000]\n",
      "\n",
      "Processed 3000 parameter combinations\n",
      "\n",
      "✓ Successfully stored 3000 maps in memory\n",
      "  First map shape: (256, 256)\n",
      "  Memory usage: ~1.57 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "import limpy.lines as ll\n",
    "import limpy.powerspectra as lp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "class LIMpyGenerator:\n",
    "    \"\"\"\n",
    "    Generate Line Intensity Maps with flexible parameter combinations.\n",
    "    \n",
    "    Two operational modes:\n",
    "    1. VARYING COSMOLOGY: Different halo catalogs for each parameter set (cosmo + astro params)\n",
    "    2. FIXED COSMOLOGY: Single halo catalog with varying astrophysical parameters only\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, boxsize=80.0, ngrid=256, redshift=3.6, \n",
    "                 line_name='CII158', model_name='Alma_scaling',\n",
    "                 param_names=['sigma_8', 'omega_m'], seed=42, \n",
    "                 noise_level=1e1, noise_mode='fixed',\n",
    "                 noise_range=(1e-5, 1e3),\n",
    "                 log_noise_range=(0, 4),\n",
    "                 mode='varying_cosmology'):\n",
    "        \"\"\"\n",
    "        Initialize generator\n",
    "        \n",
    "        Args:\n",
    "            mode: 'varying_cosmology' or 'fixed_cosmology'\n",
    "            param_names: List of parameters to vary\n",
    "                - For varying_cosmology: can include cosmo + astro params\n",
    "                - For fixed_cosmology: should only include astro params (cosmo will be fixed from halocat)\n",
    "        \"\"\"\n",
    "        self.boxsize = boxsize\n",
    "        self.ngrid = ngrid\n",
    "        self.redshift = redshift\n",
    "        self.line_name = line_name\n",
    "        self.model_name = model_name\n",
    "        self.mmin = 1e9\n",
    "        self.seed = seed\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Noise configuration\n",
    "        self.noise_mode = noise_mode\n",
    "        self.noise_level = noise_level\n",
    "        self.noise_range = noise_range\n",
    "        self.log_noise_range = log_noise_range\n",
    "        \n",
    "        # Check if noise is in param_names\n",
    "        self.noise_as_param = 'noise_level' in param_names\n",
    "        self.log_noise_as_param = 'log_noise_level' in param_names\n",
    "        \n",
    "        if self.noise_as_param or self.log_noise_as_param:\n",
    "            self.noise_mode = 'varying'\n",
    "            param_names_filtered = [p for p in param_names if p not in ['noise_level', 'log_noise_level']]\n",
    "        else:\n",
    "            param_names_filtered = param_names\n",
    "        \n",
    "        # Parameter configuration\n",
    "        self.param_names_internal = param_names_filtered\n",
    "        self.param_names = param_names\n",
    "        self.cosmological_params = ['sigma_8', 'omega_m', 'h']\n",
    "        self.astrophysical_params = [p for p in param_names_filtered if p not in self.cosmological_params]\n",
    "        \n",
    "        # Validate mode and parameters\n",
    "        if mode == 'fixed_cosmology':\n",
    "            cosmo_in_params = [p for p in param_names_filtered if p in self.cosmological_params]\n",
    "            if cosmo_in_params:\n",
    "                print(f\"WARNING: In fixed_cosmology mode, cosmological parameters {cosmo_in_params} will be ignored\")\n",
    "                print(\"They will be taken from the fixed halo catalog instead\")\n",
    "        \n",
    "        print(f\"Mode: {mode}\")\n",
    "        print(f\"Parameters to vary: {self.param_names}\")\n",
    "        print(f\"  Cosmological: {[p for p in param_names_filtered if p in self.cosmological_params]}\")\n",
    "        print(f\"  Astrophysical: {self.astrophysical_params}\")\n",
    "        print(f\"Noise mode: {self.noise_mode}\")\n",
    "        \n",
    "        # Storage\n",
    "        self.params_array = None\n",
    "        self.param_ranges = {}\n",
    "        self.latin_hypercube_samples = None\n",
    "        self.noise_values = None\n",
    "        self.log_noise_values = None\n",
    "        self.intensity_maps = []\n",
    "        self.power_spectra = []\n",
    "        self.pdfs = []\n",
    "        self.k_values = None\n",
    "        self.pdf_bins = None\n",
    "        \n",
    "        # For fixed cosmology mode\n",
    "        self.fixed_halocat = None\n",
    "        self.fixed_cosmo_params = None\n",
    "        self.fixed_halocat_file = None\n",
    "    \n",
    "    def setup_parameter_ranges(self, param_ranges=None):\n",
    "        \"\"\"Setup parameter ranges for astrophysical parameters\"\"\"\n",
    "        default_ranges = {\n",
    "            'a_off': (4, 10.0),\n",
    "            'b_off': (0.0, 2.0)\n",
    "        }\n",
    "        \n",
    "        if param_ranges:\n",
    "            self.param_ranges.update(param_ranges)\n",
    "        else:\n",
    "            for param in self.astrophysical_params:\n",
    "                if param in default_ranges:\n",
    "                    self.param_ranges[param] = default_ranges[param]\n",
    "        \n",
    "        # Add noise range if treating as parameter\n",
    "        if self.noise_as_param:\n",
    "            self.param_ranges['noise_level'] = self.noise_range\n",
    "        elif self.log_noise_as_param:\n",
    "            self.param_ranges['log_noise_level'] = self.log_noise_range\n",
    "    \n",
    "    def generate_latin_hypercube_samples(self, n_samples):\n",
    "        \"\"\"Generate Latin hypercube samples for astrophysical parameters\"\"\"\n",
    "        n_astro_params = len(self.astrophysical_params)\n",
    "        \n",
    "        if n_astro_params == 0:\n",
    "            print(\"No astrophysical parameters to sample\")\n",
    "            self.latin_hypercube_samples = None\n",
    "            return None\n",
    "        \n",
    "        sampler = qmc.LatinHypercube(d=n_astro_params, seed=self.seed)\n",
    "        samples_unit = sampler.random(n=n_samples)\n",
    "        \n",
    "        samples_scaled = np.zeros((n_samples, n_astro_params))\n",
    "        for i, param in enumerate(self.astrophysical_params):\n",
    "            low, high = self.param_ranges[param]\n",
    "            samples_scaled[:, i] = qmc.scale(samples_unit[:, i:i+1], low, high).flatten()\n",
    "        \n",
    "        self.latin_hypercube_samples = samples_scaled\n",
    "        \n",
    "        print(f\"Generated {n_samples} Latin hypercube samples for {self.astrophysical_params}\")\n",
    "        for i, param in enumerate(self.astrophysical_params):\n",
    "            print(f\"  {param}: [{samples_scaled[:, i].min():.3f}, {samples_scaled[:, i].max():.3f}]\")\n",
    "        \n",
    "        return samples_scaled\n",
    "    \n",
    "    def generate_noise_levels(self, n_samples, method='uniform'):\n",
    "        \"\"\"Generate noise levels for varying noise mode\"\"\"\n",
    "        if self.noise_mode == 'fixed':\n",
    "            self.noise_values = np.full(n_samples, self.noise_level)\n",
    "            self.log_noise_values = np.log10(self.noise_values)\n",
    "            return self.noise_values\n",
    "        \n",
    "        rng = np.random.RandomState(self.seed + 1000)\n",
    "        \n",
    "        if self.log_noise_as_param:\n",
    "            log_min, log_max = self.log_noise_range\n",
    "            \n",
    "            if method == 'uniform' or method == 'log_uniform':\n",
    "                log_noise_levels = rng.uniform(log_min, log_max, n_samples)\n",
    "            elif method == 'latin_hypercube':\n",
    "                sampler = qmc.LatinHypercube(d=1, seed=self.seed + 1000)\n",
    "                samples = sampler.random(n=n_samples)\n",
    "                log_noise_levels = qmc.scale(samples, log_min, log_max).flatten()\n",
    "            \n",
    "            self.log_noise_values = log_noise_levels\n",
    "            self.noise_values = 10**log_noise_levels\n",
    "        else:\n",
    "            min_noise, max_noise = self.noise_range\n",
    "            \n",
    "            if method == 'uniform':\n",
    "                noise_levels = rng.uniform(min_noise, max_noise, n_samples)\n",
    "            elif method == 'log_uniform':\n",
    "                log_min = np.log10(min_noise)\n",
    "                log_max = np.log10(max_noise)\n",
    "                noise_levels = 10**rng.uniform(log_min, log_max, n_samples)\n",
    "            elif method == 'latin_hypercube':\n",
    "                sampler = qmc.LatinHypercube(d=1, seed=self.seed + 1000)\n",
    "                samples = sampler.random(n=n_samples)\n",
    "                log_min = np.log10(min_noise)\n",
    "                log_max = np.log10(max_noise)\n",
    "                noise_levels = 10**qmc.scale(samples, log_min, log_max).flatten()\n",
    "            \n",
    "            self.noise_values = noise_levels\n",
    "            self.log_noise_values = np.log10(noise_levels)\n",
    "        \n",
    "        return self.noise_values\n",
    "    \n",
    "    def load_fixed_halocat(self, halocat_file):\n",
    "        \"\"\"Load a single halo catalog for fixed cosmology mode\"\"\"\n",
    "        self.fixed_halocat_file = halocat_file\n",
    "        data = np.load(halocat_file, allow_pickle=True)\n",
    "        \n",
    "        # Extract cosmological parameters\n",
    "        if 'params' in data:\n",
    "            params = data['params']\n",
    "            if hasattr(params, 'item'):\n",
    "                params = params.item()\n",
    "        else:\n",
    "            params = {}\n",
    "        \n",
    "        self.fixed_cosmo_params = {\n",
    "            'sigma_8': params.get('sigma_8', params.get('sigma8', 0.8)),\n",
    "            'omega_m': params.get('omega_m', params.get('Omega_m', 0.3)),\n",
    "            'h': params.get('h', 0.7)\n",
    "        }\n",
    "        \n",
    "        self.fixed_halocat = data\n",
    "        \n",
    "        print(f\"Fixed cosmology loaded from {Path(halocat_file).name}:\")\n",
    "        for key, val in self.fixed_cosmo_params.items():\n",
    "            print(f\"  {key} = {val:.3f}\")\n",
    "        \n",
    "        return self.fixed_cosmo_params\n",
    "    \n",
    "    def process_batch(self, halocat_files=None, n_samples=None, store_maps=False):\n",
    "        \"\"\"\n",
    "        Main processing method that handles both modes\n",
    "        \n",
    "        For varying_cosmology mode:\n",
    "            - Requires halocat_files (list of paths)\n",
    "            - Each halocat provides its own cosmology\n",
    "            \n",
    "        For fixed_cosmology mode:\n",
    "            - Requires n_samples (number of realizations)\n",
    "            - Must call load_fixed_halocat() first\n",
    "        \"\"\"\n",
    "        if self.mode == 'fixed_cosmology':\n",
    "            if self.fixed_halocat is None:\n",
    "                raise ValueError(\"For fixed_cosmology mode, call load_fixed_halocat() first\")\n",
    "            return self._process_fixed_cosmology_batch(n_samples, store_maps)\n",
    "        else:\n",
    "            if halocat_files is None:\n",
    "                raise ValueError(\"For varying_cosmology mode, provide halocat_files\")\n",
    "            return self._process_varying_cosmology_batch(halocat_files, store_maps)\n",
    "    \n",
    "    def _process_fixed_cosmology_batch(self, n_samples, store_maps):\n",
    "        \"\"\"Process with fixed cosmology, varying only astrophysics\"\"\"\n",
    "        if n_samples is None:\n",
    "            raise ValueError(\"Specify n_samples for fixed_cosmology mode\")\n",
    "        \n",
    "        # Generate astrophysical parameters if needed\n",
    "        if self.astrophysical_params and self.latin_hypercube_samples is None:\n",
    "            self.generate_latin_hypercube_samples(n_samples)\n",
    "        \n",
    "        # Generate noise levels\n",
    "        noise_levels = self.generate_noise_levels(n_samples, method='latin_hypercube')\n",
    "        \n",
    "        rng = np.random.RandomState(self.seed)\n",
    "        \n",
    "        all_params = []\n",
    "        all_pk = []\n",
    "        all_pdf = []\n",
    "        \n",
    "        print(f\"\\nProcessing {n_samples} realizations with fixed cosmology\")\n",
    "        print(f\"Fixed cosmology: {self.fixed_cosmo_params}\")\n",
    "        print(f\"Store maps: {store_maps}\")\n",
    "        \n",
    "        for i in tqdm(range(n_samples), desc=\"Processing\"):\n",
    "            try:\n",
    "                # Build parameters\n",
    "                params_internal = self.fixed_cosmo_params.copy()\n",
    "                \n",
    "                # Add astrophysical parameters\n",
    "                if self.latin_hypercube_samples is not None:\n",
    "                    for j, param in enumerate(self.astrophysical_params):\n",
    "                        params_internal[param] = self.latin_hypercube_samples[i, j]\n",
    "                \n",
    "                # Process with LIMpy\n",
    "                intensity_2d, _, _ = self.process_single_halocat(\n",
    "                    self.fixed_halocat_file, \n",
    "                    index=i, \n",
    "                    astro_params=self.latin_hypercube_samples[i] if self.latin_hypercube_samples is not None else None\n",
    "                )\n",
    "                \n",
    "                # Add noise\n",
    "                current_noise_level = noise_levels[i]\n",
    "                noise = rng.normal(0, current_noise_level, intensity_2d.shape)\n",
    "                intensity_2d_noisy = intensity_2d + noise\n",
    "                \n",
    "                # FIXED: Store maps if requested\n",
    "                if store_maps:\n",
    "                    self.intensity_maps.append(intensity_2d_noisy.copy())\n",
    "                \n",
    "                # Compute observables\n",
    "                k, pk = self.compute_power_spectrum_2d(intensity_2d_noisy)\n",
    "                bins, pdf = self.compute_pdf(intensity_2d_noisy, n_bins=40)\n",
    "                \n",
    "                # Store parameters (only the ones we're varying)\n",
    "                param_values = []\n",
    "                for param_name in self.param_names_internal:\n",
    "                    if param_name in self.cosmological_params:\n",
    "                        # For fixed cosmology mode, still include cosmo params in output if requested\n",
    "                        param_values.append(params_internal[param_name])\n",
    "                    else:\n",
    "                        param_values.append(params_internal[param_name])\n",
    "                \n",
    "                # Add noise parameter if varying\n",
    "                if self.log_noise_as_param:\n",
    "                    param_values.append(self.log_noise_values[i])\n",
    "                elif self.noise_as_param:\n",
    "                    param_values.append(current_noise_level)\n",
    "                \n",
    "                all_params.append(param_values)\n",
    "                all_pk.append(pk)\n",
    "                all_pdf.append(pdf)\n",
    "                \n",
    "                if self.k_values is None:\n",
    "                    self.k_values = k\n",
    "                if self.pdf_bins is None:\n",
    "                    self.pdf_bins = bins\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {i}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        self.params_array = np.array(all_params)\n",
    "        self.power_spectra = all_pk\n",
    "        self.pdfs = all_pdf\n",
    "        \n",
    "        print(f\"\\nStored {len(self.intensity_maps)} maps in memory\")\n",
    "        \n",
    "        return len(all_params)\n",
    "    \n",
    "    def _process_varying_cosmology_batch(self, halocat_files, store_maps):\n",
    "        \"\"\"Process with varying cosmology using different halocats\"\"\"\n",
    "        n_files = len(halocat_files)\n",
    "        \n",
    "        # Generate astrophysical parameters if needed\n",
    "        if self.astrophysical_params and self.latin_hypercube_samples is None:\n",
    "            self.generate_latin_hypercube_samples(n_files)\n",
    "        \n",
    "        # Generate noise levels\n",
    "        noise_levels = self.generate_noise_levels(n_files, method='latin_hypercube')\n",
    "        \n",
    "        rng = np.random.RandomState(self.seed)\n",
    "        \n",
    "        all_params = []\n",
    "        all_pk = []\n",
    "        all_pdf = []\n",
    "        \n",
    "        print(f\"\\nProcessing {n_files} halocats with varying cosmology\")\n",
    "        print(f\"Store maps: {store_maps}\")\n",
    "        \n",
    "        for i, halocat_file in enumerate(tqdm(halocat_files, desc=\"Processing\")):\n",
    "            try:\n",
    "                astro_params = None\n",
    "                if self.latin_hypercube_samples is not None:\n",
    "                    astro_params = self.latin_hypercube_samples[i]\n",
    "                \n",
    "                intensity_2d, _, params = self.process_single_halocat(\n",
    "                    halocat_file, index=i, astro_params=astro_params\n",
    "                )\n",
    "                \n",
    "                # Add noise\n",
    "                current_noise_level = noise_levels[i]\n",
    "                noise = rng.normal(0, current_noise_level, intensity_2d.shape)\n",
    "                intensity_2d_noisy = intensity_2d + noise\n",
    "                \n",
    "                # FIXED: Store maps if requested\n",
    "                if store_maps:\n",
    "                    self.intensity_maps.append(intensity_2d_noisy.copy())\n",
    "                \n",
    "                # Compute observables\n",
    "                k, pk = self.compute_power_spectrum_2d(intensity_2d_noisy)\n",
    "                bins, pdf = self.compute_pdf(intensity_2d_noisy, n_bins=40)\n",
    "                \n",
    "                # Store parameters\n",
    "                param_values = [params[p] for p in self.param_names_internal]\n",
    "                if self.log_noise_as_param:\n",
    "                    param_values.append(self.log_noise_values[i])\n",
    "                elif self.noise_as_param:\n",
    "                    param_values.append(current_noise_level)\n",
    "                \n",
    "                all_params.append(param_values)\n",
    "                all_pk.append(pk)\n",
    "                all_pdf.append(pdf)\n",
    "                \n",
    "                if self.k_values is None:\n",
    "                    self.k_values = k\n",
    "                if self.pdf_bins is None:\n",
    "                    self.pdf_bins = bins\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {halocat_file.name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        self.params_array = np.array(all_params)\n",
    "        self.power_spectra = all_pk\n",
    "        self.pdfs = all_pdf\n",
    "        \n",
    "        print(f\"\\nStored {len(self.intensity_maps)} maps in memory\")\n",
    "        \n",
    "        return len(all_params)\n",
    "    \n",
    "    def process_single_halocat(self, halocat_file, index=0, astro_params=None):\n",
    "        \"\"\"Process single halocat with parameter combination\"\"\"\n",
    "        data = np.load(halocat_file, allow_pickle=True)\n",
    "        \n",
    "        if 'params' in data:\n",
    "            params = data['params']\n",
    "            if hasattr(params, 'item'):\n",
    "                params = params.item()\n",
    "        else:\n",
    "            params = {}\n",
    "        \n",
    "        # Build parameter dictionary\n",
    "        params_internal = {}\n",
    "        \n",
    "        # Add cosmological parameters\n",
    "        for cosmo_param in ['sigma_8', 'omega_m', 'h']:\n",
    "            if cosmo_param == 'sigma_8':\n",
    "                params_internal['sigma_8'] = params.get('sigma_8', params.get('sigma8', 0.8))\n",
    "            elif cosmo_param == 'omega_m':\n",
    "                params_internal['omega_m'] = params.get('omega_m', params.get('Omega_m', 0.3))\n",
    "            elif cosmo_param == 'h':\n",
    "                params_internal['h'] = params.get('h', 0.7)\n",
    "        \n",
    "        # Add astrophysical parameters\n",
    "        if astro_params is not None:\n",
    "            for i, param in enumerate(self.astrophysical_params):\n",
    "                params_internal[param] = astro_params[i]\n",
    "        \n",
    "        # Fix boundary conditions\n",
    "        halocat_file_to_use = self._fix_boundary_conditions(data, halocat_file)\n",
    "        \n",
    "        try:\n",
    "            lim_sim = ll.lim_sims(\n",
    "                halocat_file_to_use,\n",
    "                self.redshift,\n",
    "                model_name=self.model_name,\n",
    "                line_name=self.line_name,\n",
    "                halo_cutoff_mass=self.mmin,\n",
    "                halocat_type=\"input_cat\",\n",
    "                parameters=params_internal,\n",
    "                ngrid_x=self.ngrid,\n",
    "                ngrid_y=self.ngrid,\n",
    "                ngrid_z=self.ngrid,\n",
    "                boxsize_x=self.boxsize,\n",
    "                boxsize_y=self.boxsize,\n",
    "                boxsize_z=self.boxsize,\n",
    "                nu_obs=220,\n",
    "                theta_fwhm=1,\n",
    "                dnu_obs=2.2\n",
    "            )\n",
    "            \n",
    "            intensity_3d = lim_sim.make_intensity_grid()\n",
    "            intensity_2d = np.mean(intensity_3d, axis=2)\n",
    "            \n",
    "        finally:\n",
    "            if halocat_file_to_use != str(halocat_file):\n",
    "                import os\n",
    "                try:\n",
    "                    os.unlink(halocat_file_to_use)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return intensity_2d, intensity_3d, params_internal\n",
    "    \n",
    "    def _fix_boundary_conditions(self, data, halocat_file):\n",
    "        \"\"\"Fix boundary conditions in halo positions\"\"\"\n",
    "        import tempfile\n",
    "        \n",
    "        if 'x' in data or 'X' in data or 'pos' in data:\n",
    "            temp_file = tempfile.NamedTemporaryFile(suffix='.npz', delete=False)\n",
    "            save_dict = {key: data[key] for key in data.keys()}\n",
    "            \n",
    "            if 'pos' in data:\n",
    "                positions = data['pos'].copy()\n",
    "                positions = positions % self.boxsize\n",
    "                positions[positions >= self.boxsize] = self.boxsize - 1e-6\n",
    "                save_dict['pos'] = positions\n",
    "            else:\n",
    "                for coord in ['x', 'X', 'y', 'Y', 'z', 'Z']:\n",
    "                    if coord in data:\n",
    "                        pos = data[coord].copy()\n",
    "                        pos = pos % self.boxsize\n",
    "                        pos[pos >= self.boxsize] = self.boxsize - 1e-6\n",
    "                        save_dict[coord] = pos\n",
    "            \n",
    "            np.savez(temp_file.name, **save_dict)\n",
    "            return temp_file.name\n",
    "        return str(halocat_file)\n",
    "    \n",
    "    def compute_power_spectrum_2d(self, intensity_2d):\n",
    "        \"\"\"Compute 2D power spectrum\"\"\"\n",
    "        k, pk = lp.get_pk2d(intensity_2d, self.boxsize, self.boxsize, \n",
    "                           self.ngrid, self.ngrid)\n",
    "        return k, pk\n",
    "    \n",
    "    def compute_pdf(self, intensity_map, n_bins=40):\n",
    "        \"\"\"Compute PDF\"\"\"\n",
    "        flat_intensity = intensity_map.flatten()\n",
    "        bin_edges = np.linspace(flat_intensity.min(), flat_intensity.max(), n_bins + 1)\n",
    "        pdf, _ = np.histogram(flat_intensity, bins=bin_edges, density=True)\n",
    "        return bin_edges, pdf\n",
    "    \n",
    "    def save_results(self, output_dir, seed=None, save_intensity_maps=False):\n",
    "        \"\"\"\n",
    "        Save results with metadata\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save results\n",
    "            seed: Random seed for file naming\n",
    "            save_intensity_maps: If True, save intensity maps to disk (can be large!)\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            seed = self.seed\n",
    "        \n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create structured array\n",
    "        dtype_list = [(name, '<f8') for name in self.param_names]\n",
    "        params_structured = np.zeros(len(self.params_array), dtype=dtype_list)\n",
    "        \n",
    "        for i, param_vals in enumerate(self.params_array):\n",
    "            params_structured[i] = tuple(param_vals)\n",
    "        \n",
    "        # File naming\n",
    "        ps_file = output_path / f\"ps_80_256.npz\"\n",
    "        pdf_file = output_path / f\"pdf_80_256.npz\"\n",
    "        \n",
    "        all_k = np.array([self.k_values] * len(self.power_spectra))\n",
    "        \n",
    "        # Metadata\n",
    "        metadata = {\n",
    "            'seed': seed,\n",
    "            'mode': self.mode,\n",
    "            'noise_mode': self.noise_mode,\n",
    "        }\n",
    "        \n",
    "        if self.noise_mode == 'fixed':\n",
    "            metadata['noise_level'] = self.noise_level\n",
    "        else:\n",
    "            if self.log_noise_as_param:\n",
    "                metadata['log_noise_range'] = self.log_noise_range\n",
    "                metadata['log_noise_values'] = self.log_noise_values\n",
    "            else:\n",
    "                metadata['noise_range'] = self.noise_range\n",
    "            metadata['noise_values'] = self.noise_values\n",
    "        \n",
    "        if self.mode == 'fixed_cosmology' and self.fixed_cosmo_params:\n",
    "            metadata['fixed_cosmology'] = self.fixed_cosmo_params\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            ps_file,\n",
    "            parameters=params_structured,\n",
    "            k_2d=all_k,\n",
    "            pk_2d=np.array(self.power_spectra),\n",
    "            **metadata\n",
    "        )\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            pdf_file,\n",
    "            parameters=params_structured,\n",
    "            lim_bin_edges_linear_2d=self.pdf_bins,\n",
    "            lim_pdf_linear_2d=np.array(self.pdfs),\n",
    "            **metadata\n",
    "        )\n",
    "        \n",
    "        # Save intensity maps if requested and available\n",
    "        if save_intensity_maps and len(self.intensity_maps) > 0:\n",
    "            maps_file = output_path / f\"intensity_maps_80_256.npz\"\n",
    "            print(f\"\\nSaving {len(self.intensity_maps)} intensity maps to disk...\")\n",
    "            np.savez_compressed(\n",
    "                maps_file,\n",
    "                parameters=params_structured,\n",
    "                intensity_maps=np.array(self.intensity_maps),\n",
    "                **metadata\n",
    "            )\n",
    "            print(f\"  Intensity maps: {maps_file}\")\n",
    "            print(f\"  File size: ~{maps_file.stat().st_size / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Save parameter configuration\n",
    "        config = {\n",
    "            'mode': self.mode,\n",
    "            'param_names': self.param_names,\n",
    "            'param_ranges': self.param_ranges,\n",
    "            'seed': seed,\n",
    "            'noise_mode': self.noise_mode,\n",
    "            'noise_level': self.noise_level if self.noise_mode == 'fixed' else None,\n",
    "            'noise_range': self.noise_range if self.noise_as_param else None,\n",
    "            'log_noise_range': self.log_noise_range if self.log_noise_as_param else None,\n",
    "            'boxsize': self.boxsize,\n",
    "            'ngrid': self.ngrid,\n",
    "            'redshift': self.redshift,\n",
    "            'line_name': self.line_name,\n",
    "            'model_name': self.model_name,\n",
    "            'n_maps_stored': len(self.intensity_maps)\n",
    "        }\n",
    "        \n",
    "        if self.mode == 'fixed_cosmology' and self.fixed_cosmo_params:\n",
    "            config['fixed_cosmology'] = self.fixed_cosmo_params\n",
    "        \n",
    "        config_file = output_path / 'parameter_config.json'\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nResults saved:\")\n",
    "        print(f\"  Power spectra: {ps_file}\")\n",
    "        print(f\"  PDFs: {pdf_file}\")\n",
    "        print(f\"  Config: {config_file}\")\n",
    "        print(f\"\\nMode: {self.mode}\")\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(f\"Maps stored in memory: {len(self.intensity_maps)}\")\n",
    "        print(f\"\\nParameter summary ({len(self.params_array)} samples):\")\n",
    "        for i, name in enumerate(self.param_names):\n",
    "            values = self.params_array[:, i]\n",
    "            print(f\"  {name}: [{values.min():.3f}, {values.max():.3f}]\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "def example_varying_cosmology(n_maps=100, input_dir=None, output_dir=None, \n",
    "                              store_maps=False, seed=42, noise_level=1e-5):\n",
    "    \"\"\"\n",
    "    EXAMPLE 1: Varying Cosmology Mode\n",
    "    Uses different halo catalogs, each with its own cosmology\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXAMPLE 1: VARYING COSMOLOGY MODE\")\n",
    "    print(\"Uses different halo catalogs for each parameter combination\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if input_dir is None:\n",
    "        input_dir = Path(\"/Users/anirbanroy/Desktop/halocats/\")\n",
    "    else:\n",
    "        input_dir = Path(input_dir)\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = f\"/Users/anirbanroy/Desktop/processed_varying_cosmo_{n_maps}maps/\"\n",
    "    \n",
    "    generator = LIMpyGenerator(\n",
    "        param_names=['sigma_8', 'omega_m', 'a_off', 'b_off'],\n",
    "        mode='varying_cosmology',\n",
    "        seed=seed,\n",
    "        noise_level=noise_level,\n",
    "        noise_mode='fixed'\n",
    "    )\n",
    "    \n",
    "    generator.setup_parameter_ranges({\n",
    "        'a_off': (4, 10),\n",
    "        'b_off': (0, 2)\n",
    "    })\n",
    "    \n",
    "    all_halocat_files = sorted(input_dir.glob(\"halocat_*.npz\"))\n",
    "    \n",
    "    if len(all_halocat_files) < n_maps:\n",
    "        print(f\"WARNING: Only {len(all_halocat_files)} halo catalogs available, but {n_maps} requested\")\n",
    "        n_maps = len(all_halocat_files)\n",
    "    \n",
    "    halocat_files = all_halocat_files[:n_maps]\n",
    "    \n",
    "    print(f\"\\nProcessing {len(halocat_files)} halo catalogs\")\n",
    "    print(\"Each catalog provides its own cosmology (sigma_8, omega_m)\")\n",
    "    print(\"Astrophysical parameters (a_off, b_off) are sampled via Latin hypercube\")\n",
    "    print(f\"Store maps in memory: {store_maps}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    n_processed = generator.process_batch(\n",
    "        halocat_files=halocat_files,\n",
    "        store_maps=store_maps\n",
    "    )\n",
    "    \n",
    "    generator.save_results(output_dir, seed=seed, save_intensity_maps=store_maps)\n",
    "    \n",
    "    print(f\"\\nProcessed {n_processed} parameter combinations\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def example_fixed_cosmology(n_maps=100, input_dir=None, output_dir=None, \n",
    "                              store_maps=False, seed=42, noise_level=1e-5):\n",
    "    \"\"\"\n",
    "    EXAMPLE 2: Fixed Cosmology Mode\n",
    "    Uses ONE halo catalog repeatedly with different astrophysical parameters\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXAMPLE 2: FIXED COSMOLOGY MODE\")\n",
    "    print(\"Uses single halo catalog with varying astrophysical parameters only\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    generator = LIMpyGenerator(\n",
    "        param_names=['a_off', 'b_off'],\n",
    "        mode='fixed_cosmology',\n",
    "        seed=seed,\n",
    "        noise_level=noise_level,\n",
    "        noise_mode='fixed'\n",
    "    )\n",
    "    \n",
    "    generator.setup_parameter_ranges({\n",
    "        'a_off': (4, 10),\n",
    "        'b_off': (0, 2)\n",
    "    })\n",
    "    \n",
    "    single_halocat = \"/Users/anirbanroy/Desktop/halocats/halocat_1396.npz\"\n",
    "    fixed_cosmo = generator.load_fixed_halocat(single_halocat)\n",
    "    \n",
    "    print(f\"\\nGenerating {n_maps} realizations with fixed cosmology\")\n",
    "    print(\"Only astrophysical parameters (a_off, b_off) will vary\")\n",
    "    \n",
    "    n_processed = generator.process_batch(\n",
    "        n_samples=n_maps,\n",
    "        store_maps=store_maps\n",
    "    )\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = \"/Users/anirbanroy/Desktop/processed_fixed_cosmo/\"\n",
    "    generator.save_results(output_dir, seed=seed, save_intensity_maps=store_maps)\n",
    "    \n",
    "    print(f\"\\nProcessed {n_processed} parameter combinations\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def example_fixed_cosmology_with_noise(n_maps=100, seed=42):\n",
    "    \"\"\"\n",
    "    EXAMPLE 3: Fixed Cosmology with Noise as Parameter\n",
    "    Uses ONE halo catalog with varying astrophysical parameters AND noise\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXAMPLE 3: FIXED COSMOLOGY WITH NOISE AS PARAMETER\")\n",
    "    print(\"Uses single halo catalog with varying astro params + noise level\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    generator = LIMpyGenerator(\n",
    "        param_names=['sigma_8', 'omega_m', 'a_off', 'b_off', 'log_noise_level'],\n",
    "        mode='fixed_cosmology',\n",
    "        seed=seed,\n",
    "        log_noise_range=(0, 4),\n",
    "    )\n",
    "    \n",
    "    generator.setup_parameter_ranges({\n",
    "        'a_off': (4, 10),\n",
    "        'b_off': (0, 2)\n",
    "    })\n",
    "    \n",
    "    single_halocat = \"/Users/anirbanroy/Desktop/halocats/halocat_1396.npz\"\n",
    "    generator.load_fixed_halocat(single_halocat)\n",
    "    \n",
    "    print(f\"\\nGenerating {n_maps} realizations with:\")\n",
    "    print(\"  - Fixed cosmology from halocat\")\n",
    "    print(\"  - Varying a_off and b_off\")\n",
    "    print(\"  - Varying log_noise_level from 0 to 4\")\n",
    "    \n",
    "    n_processed = generator.process_batch(\n",
    "        n_samples=n_maps,\n",
    "        store_maps=True\n",
    "    )\n",
    "    \n",
    "    output_dir = \"/Users/anirbanroy/Desktop/processed_fixed_cosmo_with_noise/\"\n",
    "    generator.save_results(output_dir, seed=seed, save_intensity_maps=store_maps)\n",
    "    \n",
    "    print(f\"\\nProcessed {n_processed} parameter combinations\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def example_hybrid_mode(n_maps=50, seed=42):\n",
    "    \"\"\"\n",
    "    EXAMPLE 4: Hybrid - Include cosmo params in output even with fixed cosmology\n",
    "    This is useful when you want the output to have cosmo params for compatibility\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXAMPLE 4: FIXED COSMOLOGY BUT INCLUDE COSMO PARAMS IN OUTPUT\")\n",
    "    print(\"Useful for maintaining consistent output format\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    generator = LIMpyGenerator(\n",
    "        param_names=['sigma_8', 'omega_m', 'a_off', 'b_off'],\n",
    "        mode='fixed_cosmology',\n",
    "        seed=seed,\n",
    "        noise_level=1e-5,\n",
    "        noise_mode='fixed'\n",
    "    )\n",
    "    \n",
    "    generator.setup_parameter_ranges({\n",
    "        'a_off': (4, 10),\n",
    "        'b_off': (0, 2)\n",
    "    })\n",
    "    \n",
    "    single_halocat = \"/Users/anirbanroy/Desktop/halocats/halocat_1396.npz\"\n",
    "    fixed_cosmo = generator.load_fixed_halocat(single_halocat)\n",
    "    \n",
    "    print(\"\\nNote: sigma_8 and omega_m will be fixed from the halocat\")\n",
    "    print(\"They will appear in the output but with constant values\")\n",
    "    \n",
    "    n_processed = generator.process_batch(\n",
    "        n_samples=n_maps,\n",
    "        store_maps=False\n",
    "    )\n",
    "    \n",
    "    output_dir = \"/Users/anirbanroy/Desktop/processed_hybrid/\"\n",
    "    generator.save_results(output_dir, seed=seed, save_intensity_maps=store_maps)\n",
    "    \n",
    "    print(f\"\\nProcessed {n_processed} parameter combinations\")\n",
    "    print(\"Output will have 4 parameters, but sigma_8 and omega_m are constant\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def example_varying_all_parameters(n_maps=3000, input_dir=None, output_dir=None, \n",
    "                                  store_maps=False, seed=42):\n",
    "    \"\"\"\n",
    "    EXAMPLE 5: Varying Cosmology + Astrophysics + Noise\n",
    "    Uses different halo catalogs (varying cosmology) with varying astro params and noise\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXAMPLE 5: VARYING ALL PARAMETERS (COSMO + ASTRO + NOISE)\")\n",
    "    print(\"Uses different halo catalogs with varying everything\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if input_dir is None:\n",
    "        input_dir = Path(\"/Users/anirbanroy/Desktop/halocats/\")\n",
    "    else:\n",
    "        input_dir = Path(input_dir)\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = f\"/Users/anirbanroy/Desktop/processed_all_params_noise_{n_maps}maps/\"\n",
    "    \n",
    "    generator = LIMpyGenerator(\n",
    "        param_names=['sigma_8', 'omega_m', 'a_off', 'b_off', 'log_noise_level'],\n",
    "        mode='varying_cosmology',\n",
    "        seed=seed,\n",
    "        log_noise_range=(-5, 3),\n",
    "    )\n",
    "    \n",
    "    generator.setup_parameter_ranges({\n",
    "        'a_off': (4, 10),\n",
    "        'b_off': (0, 2)\n",
    "    })\n",
    "    \n",
    "    all_halocat_files = sorted(input_dir.glob(\"halocat_*.npz\"))\n",
    "    \n",
    "    if len(all_halocat_files) < n_maps:\n",
    "        print(f\"WARNING: Only {len(all_halocat_files)} halo catalogs available, but {n_maps} requested\")\n",
    "        n_maps = len(all_halocat_files)\n",
    "    \n",
    "    halocat_files = all_halocat_files[:n_maps]\n",
    "    \n",
    "    print(f\"\\nProcessing {len(halocat_files)} halo catalogs\")\n",
    "    print(\"Parameters varying:\")\n",
    "    print(\"  - sigma_8, omega_m: from halo catalogs\")\n",
    "    print(\"  - a_off: [4, 10]\")\n",
    "    print(\"  - b_off: [0, 2]\")\n",
    "    print(f\"  - log_noise_level: [{generator.log_noise_range[0]}, {generator.log_noise_range[1]}]\")\n",
    "    print(f\"    (noise level: [10^{generator.log_noise_range[0]:.1f}, 10^{generator.log_noise_range[1]:.1f}])\")\n",
    "    print(f\"Store maps in memory: {store_maps}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    n_processed = generator.process_batch(\n",
    "        halocat_files=halocat_files,\n",
    "        store_maps=store_maps\n",
    "    )\n",
    "    \n",
    "    generator.save_results(output_dir, seed=seed, save_intensity_maps=store_maps)\n",
    "    \n",
    "    print(f\"\\nProcessed {n_processed} parameter combinations\")\n",
    "    print(\"\\nParameter summary:\")\n",
    "    for i, name in enumerate(generator.param_names):\n",
    "        values = generator.params_array[:, i]\n",
    "        print(f\"  {name}: [{values.min():.3f}, {values.max():.3f}] (mean={values.mean():.3f}, std={values.std():.3f})\")\n",
    "    \n",
    "    if generator.log_noise_values is not None:\n",
    "        print(f\"\\nNoise level distribution:\")\n",
    "        print(f\"  Min noise: {10**generator.log_noise_values.min():.2e}\")\n",
    "        print(f\"  Max noise: {10**generator.log_noise_values.max():.2e}\")\n",
    "        print(f\"  Median noise: {10**np.median(generator.log_noise_values):.2e}\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ========================================================================\n",
    "    # QUICK EXAMPLES - Uncomment the one you want to run\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Example 1: Varying cosmology with 10 maps\n",
    "    # generator = example_varying_cosmology(n_maps=10, store_maps=True)\n",
    "    \n",
    "    generator = example_varying_cosmology(\n",
    "        n_maps=3000,\n",
    "        input_dir=\"/Users/anirbanroy/Desktop/halocats/\",\n",
    "        output_dir=\"/Users/anirbanroy/Desktop/test_maps_all_params/\",\n",
    "        store_maps=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Example 2: Varying cosmology with 3000 maps (full dataset)\n",
    "    # generator = example_varying_cosmology(n_maps=3000, store_maps=False)\n",
    "    \n",
    "    # Example 3: Varying all parameters including noise\n",
    "    #generator = example_varying_all_parameters(\n",
    "    #    n_maps=3000,\n",
    "    #    input_dir=\"/Users/anirbanroy/Desktop/halocats/\",\n",
    "    #    output_dir=\"/Users/anirbanroy/Desktop/test_maps_all_params_varying_noise/\",\n",
    "    #    store_maps=True,\n",
    "    #    seed=42\n",
    "    #)\n",
    "    \n",
    "    # Example 4: Fixed cosmology mode\n",
    "    # generator = example_fixed_cosmology(n_maps=100, store_maps=True)\n",
    "    \n",
    "    # Example 5: Fixed cosmology with noise as parameter\n",
    "    # generator = example_fixed_cosmology_with_noise(n_maps=100)\n",
    "    \n",
    "    # Example 6: Hybrid mode for compatibility\n",
    "    # generator = example_hybrid_mode(n_maps=50)\n",
    "    \n",
    "    # Optional: Check if maps were stored\n",
    "    if generator and len(generator.intensity_maps) > 0:\n",
    "        print(f\"\\n✓ Successfully stored {len(generator.intensity_maps)} maps in memory\")\n",
    "        print(f\"  First map shape: {generator.intensity_maps[0].shape}\")\n",
    "        print(f\"  Memory usage: ~{len(generator.intensity_maps) * generator.intensity_maps[0].nbytes / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c78ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
